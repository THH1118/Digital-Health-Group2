# -*- coding: utf-8 -*-
"""op_success_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-zHME84c84WpjX3K0akP1CfBOWtwRJ4F
"""

# ===========================================
# Two-Stage + Calibration + P value ÁâàÊú¨
# ===========================================
!pip install -U imbalanced-learn xgboost scikit-learn -q

import warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt, xgboost as xgb
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
from sklearn.metrics import (roc_auc_score, roc_curve, accuracy_score,
                             precision_score, recall_score, f1_score,
                             classification_report)
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.calibration import calibration_curve, CalibratedClassifierCV

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.ensemble import EasyEnsembleClassifier


# ---------- ÂÖ¨Áî®ÂáΩÂºè ----------
def make_calibrated(model, seed=42, method="sigmoid"):
    return CalibratedClassifierCV(estimator=model, method=method, cv=5, n_jobs=-1)

def bootstrap_auc_ci(y, proba, n_boot=1000, seed=42):
    rng = np.random.default_rng(seed)
    aucs = []
    for _ in range(n_boot):
        idx = rng.integers(0, len(y), len(y))
        if len(np.unique(y[idx])) < 2:   # Âè™ÊúâÂñÆ‰∏ÄÈ°ûÂà• ‚Üí Ë∑≥ÈÅé
            continue
        aucs.append(roc_auc_score(y[idx], proba[idx]))
    return np.percentile(aucs, [2.5, 97.5]), np.array(aucs)

def p_value_vs_baseline(boot_model, boot_base):
    diff = boot_model - boot_base
    return 2 * min((diff <= 0).mean(), (diff >= 0).mean())

def best_cutoff(y, proba):
    fpr, tpr, thr = roc_curve(y, proba)
    idx = np.argmax(tpr - fpr)
    cut = thr[idx]
    y_pred = (proba >= cut).astype(int)
    return {
        "cut-off": cut,
        "accuracy": accuracy_score(y, y_pred),
        "precision": precision_score(y, y_pred),
        "recall": recall_score(y, y_pred),
        "f1-score": f1_score(y, y_pred),
        "specificity": 1 - fpr[idx],
        "report": classification_report(y, y_pred, digits=3)
    }

from scipy.stats import weibull_min

def reliability_plot(ax, y, proba, name, bins=10, seed=42):
    prob_true, prob_pred = calibration_curve(y, proba, n_bins=bins)
    ax.plot(prob_pred, prob_true, marker="o", label=name)

    rng = np.random.default_rng(seed)
    boot_probs = []
    for _ in range(500):
        idx = rng.integers(0, len(y), len(y))
        if len(np.unique(y[idx])) < 2:
            continue
        pt, _ = calibration_curve(y[idx], proba[idx], n_bins=bins)
        if len(pt) == len(prob_pred):
            boot_probs.append(pt)

    boot_probs = np.array(boot_probs)
    if len(boot_probs) > 0:
        ci_low, ci_high = np.percentile(boot_probs, [2.5, 97.5], axis=0)
        ax.fill_between(prob_pred, ci_low, ci_high, color='gray', alpha=0.2, label='95% CI')

    # Weibull Êì¨Âêà
    c, loc, scale = weibull_min.fit(proba, floc=0)
    x = np.linspace(0, 1, 100)
    ax.plot(x, weibull_min.cdf(x, c, loc=loc, scale=scale),
            linestyle='--', color='green', label='Weibull Fit')

    ax.plot([0, 1], [0, 1], linestyle='--', color='grey')
    ax.set_title(f"Reliability ‚Äì {name}")
    ax.set_xlabel("Predicted Probability")
    ax.set_ylabel("Observed Probability")
    ax.legend()


# ---------- Two-Stage ÂâçËôïÁêÜ ----------
def prepare_data(df, target, long, short, params, cat_cols, seed=42):
    df_processed = df[long + short + [target]].copy()
    cat_cols = ["sex", "hd or capd", "dm", "htn", "op method", "thyroidectomy", "thymectomy"]
    # Áº∫ÂÄºÂ°´Ë£úÁ≠ñÁï•
    for col in df_processed.columns:
        if col in cat_cols:
            df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)
        else:
            df_processed[col].fillna(df_processed[col].mean(), inplace=True)

    X, y = df_processed.drop(columns=[target]), df_processed[target]
    X_tr, X_te, y_tr, y_te = train_test_split(X, y, stratify=y, test_size=0.2, random_state=seed)

    X_tr_long, y_tr_long = SMOTE(random_state=seed).fit_resample(X_tr[long], y_tr)

    xgb1 = xgb.XGBClassifier(**params, subsample=0.8,
                             colsample_bytree=0.8, eval_metric="auc", random_state=seed)
    xgb1.fit(X_tr_long, y_tr_long)

    risk_tr = xgb1.predict_proba(X_tr[long])[:, 1]
    risk_te = xgb1.predict_proba(X_te[long])[:, 1]

    X_tr2 = pd.concat([X_tr[short].reset_index(drop=True),
                       pd.Series(risk_tr, name="risk_score")], axis=1)
    X_te2 = pd.concat([X_te[short].reset_index(drop=True),
                       pd.Series(risk_te, name="risk_score")], axis=1)

    return X_tr2, X_te2, y_tr.reset_index(drop=True), y_te.reset_index(drop=True)


# ---------- ‰∏ªÁ®ãÂºè ----------
def run_all_models(df, target, long, short, stage1_params,
                   task_name="Task", seed=42):

    X_tr, X_te, y_tr, y_te = prepare_data(df, target, long, short, stage1_params, seed)

    models = {
        "Logistic": ImbPipeline([
            ("smote", SMOTE(random_state=seed)),
            ("scaler", StandardScaler()),
            ("clf", LogisticRegression(max_iter=1000, class_weight="balanced", random_state=seed))
        ]),

        "SVM (cal)": make_calibrated(
            ImbPipeline([
                ("smote", SMOTE(random_state=seed)),
                ("scaler", StandardScaler()),
                ("clf", SVC(probability=True, class_weight="balanced", random_state=seed))
            ]), seed),

        "kNN (cal)": make_calibrated(
            ImbPipeline([
                ("smote", SMOTE(random_state=seed)),
                ("scaler", StandardScaler()),
                ("clf", KNeighborsClassifier(n_neighbors=5))
            ]), seed),

        "EasyEnsemble (cal)": make_calibrated(
            EasyEnsembleClassifier(n_estimators=30, random_state=seed), seed),

        "Two-stage XGB (cal)": make_calibrated(
            ImbPipeline([
                ("smote", SMOTE(random_state=seed)),
                ("clf", xgb.XGBClassifier(**stage1_params,
                                          subsample=0.8, colsample_bytree=0.8,
                                          eval_metric="auc", random_state=seed))
            ]), seed),
    }

    fig, ax = plt.subplots(figsize=(6, 6))
    fig2, axs2 = plt.subplots(1, len(models), figsize=(5 * len(models), 4))

    result_dict = {}

    # ===== Ë®ìÁ∑¥ & Ë©ï‰º∞ =====
    for i, (name, model) in enumerate(models.items()):
        model.fit(X_tr, y_tr)
        proba = model.predict_proba(X_te)[:, 1]
        auc_val = roc_auc_score(y_te, proba)
        (ci_l, ci_h), boot = bootstrap_auc_ci(y_te.values, proba)
        metrics = best_cutoff(y_te, proba)

        # ROC
        fpr, tpr, _ = roc_curve(y_te, proba)
        ax.plot(fpr, tpr, label=f"{name} (AUC={auc_val:.3f})")

        # Reliability
        reliability_plot(axs2[i], y_te, proba, name)

        result_dict[name] = {
            "auc": auc_val,
            "ci": (ci_l, ci_h),
            "boot": boot,
            **{k: v for k, v in metrics.items() if k != "report"}
        }

        print(f"\nüîç [{name}] classification report:\n{metrics['report']}")

    # ===== P value vs Logistic =====
    base_boot = result_dict["Logistic"]["boot"]
    for n, info in result_dict.items():
        info["p"] = "reference" if n == "Logistic" else p_value_vs_baseline(info["boot"], base_boot)

    # ===== ÂúñË°® =====
    ax.plot([0, 1], [0, 1], ls="--", color="grey")
    ax.set_title(f"ROC ‚Äì {task_name}")
    ax.set_xlabel("False Positive Rate"); ax.set_ylabel("True Positive Rate")
    ax.legend(); plt.tight_layout(); plt.show()
    plt.tight_layout(); plt.show()

    # ===== ÊëòË¶ÅË°® =====
    tbl = []
    for n, info in result_dict.items():
        ci_l, ci_h = info["ci"]
        tbl.append({
            "Model": n,
            "AUROC (95% CI)": f"{info['auc']:.3f} ({ci_l:.3f}-{ci_h:.3f})",
            "cut-off": f"{info['cut-off']:.3f}",
            "accuracy": f"{info['accuracy']:.3f}",
            "precision": f"{info['precision']:.3f}",
            "recall": f"{info['recall']:.3f}",
            "f1-score": f"{info['f1-score']:.3f}",
            "specificity": f"{info['specificity']:.3f}",
            "P value": info["p"]
        })
    res_df = pd.DataFrame(tbl).sort_values("AUROC (95% CI)", ascending=False).reset_index(drop=True)
    print("\nüîñ ÊúÄÁµÇÁµ±Ë®àÊëòË¶ÅË°®:\n", res_df)


# ========== ËÆÄÂèñË≥áÊñô‰∏¶Âü∑Ë°å (Operation Success ÁØÑ‰æã) ==========
op_df = pd.read_excel("/content/drive/MyDrive/digital health project/op_cleanÊúÄÁµÇË≥áÊñô_0522.xlsx")
#dm„ÄÅhtn„ÄÅsex
long_cols = ["age", "sex", "bmi", "esrd yrs", "hd or capd", "dm", "htn",
             "log1p_prealk", "log1p_preca", "log1p_prep",
             "prepth", "prehb", "log1p_preca x log1p_prep", "prepth / esrd yrs"]

short_cols = ["op method", "op time √ó blood loss", "total_size",
              "total_weight", "thyroidectomy", "thymectomy"]

run_all_models(op_df, "operation_success",
               long_cols, short_cols,
               stage1_params={"n_estimators": 300, "learning_rate": 0.03,
                              "max_depth": 3, "scale_pos_weight": 0.18},
               task_name="Operation Success")